# The sgpvAM Package and Practical Recommendations for Adaptive Monitoring with the Second Generation p-value

# Introduction
In Paper 2 (Chapter 3) we present an adaptive monitoring scheme that follows studies until evidence supports either a non-trivial or non-highly actionable treatment effect. The design is very easy to implement. It can done by anyone who can think about the clinical interpretation of possible effect sizes and calculate an interval estimate for their effect, such as a support or confidence interval (CI). However, estimating the operating characteristics of a given study design is not as easy. Without tools to assist them, it could be a barrier to implementation of the method. 
In practice, the trialist will want to know the operating characteristics under the following adaptive monitoring design features.

* Frequency of looks at the data, i.e. recalculate CI at every jth subject.
* Minimum precision requirement before applying monitoring rules, i.e. check monitoring rules only if |CI| < w.
* Required observations between an alert and affirmation to stop, i.e. evaluate stopping rule j*k subjects after alert.
* Anticipated maximum amount of data that could be collected, maxN, i.e. the sample size at which the study will cease collection regardless of the stopping rules. 
* Lag time between enrolling a subject and observing their outcome measured in the number of subjects recruited during the lag, i.e. m additional subjects will be recruited in the time between one subject being recruited and that one subject’s outcome being observed.
The traditional trialist will mainly be looking for the point null Type I error probability and Power, i.e. the probability of concluding an effect is non-trivial for a given true effect size. They may also want some simple summary statistics for the potential sample sizes. We hope to provide access to these and to a more rich set of operating characteristics. Operating characteristics we can potentially estimate for a given set of design features include the following.
* Distribution of potential sample sizes.
* Point Null Type I error, when the point null is true, i.e. probability of excluding the point null from the final interval estimate. Classical trialists will want reassurance this is < 5%.
* Interval Null Type I error, when the point null is true, i.e. probability of excluding the entire trivial zone from the final interval estimate. This will be less than or equal to the point null Type I error.
* Power vs the point null, i.e. probability the final interval estimate excludes the point null for a given true effect size. This is akin to classical statistical power.
* Power vs the interval null, i.e. probability the final interval estimate excludes the null zone for a given true effect size. This will be less than or equal to the point null power, but is conceptually the preferable quantity. In better terms, this is the probability of concluding the effect is non-trivial for given true effect sizes.
* Probability of concluding effect is non-highly actionable for given true effect sizes.
* Probability of an inconclusive finding at the end of resources. Note a clinically inconclusive finding is a possibility whenever maxN is finite and/or m > 0.
* Bias, MSE, and interval coverage probability from a frequentist perspective. 
* False confirmation probability under a specified prior distribution.
To address these needs, we provide an R function, sgpvAM, that simulates the above design operating characteristics for normal and binomial outcomes, and we offer practical advice setting the minimum wait time (in terms of inferential interval width) and the number of looks before affirming an alert.


# sgpvAM Package
The sgpvAM package allows the user to obtain study design operating characteristics under a variety of settings for adaptive monitoring using the second generation p-value.  

## MCMC Replicates
The user may use the sgpvAM function to generate MCMC replicates of outcomes and intervention assignments along with an estimate of the effect and a lower- and upper- interval bound; replicates are generated using parallel computing.  Alternatively, the user may provide their own generated data together with an estimated effect and interval bounds.  When using the sgpvAM function, the user specifies the data generation function (any of the r[dist] such as rnorm) along with arguments to the function.  Similarly, the user specifies effect generation.  At this point, only fixed effects have been thoroughly tested.  However, by specifing a distribution for the effects, the user may explore False Discovery Probabilities and other operating characteristics, such as bias, dependent on distributional assumptions of the effect.

## One- vs Two-Sided Hypotheses
Clinical Guideposts defining regions of Trivial and Highly Actionable Effects must be provided though may be one- or two-sided.  The point null must be within the Trivial Region and cannot be a boundary of the region.  For general nomenclature, inputs to define the regions are: deltaL2 (the Clinically Highly Actionable Boundary less than the point null), deltaL1 (the Trivial Region Boundary less than the point null), deltaG1 (the Trivial Region Boundary greater than the point null), and deltaG2 (the Clinically Highly Actionable Boundary greater than the point null). See Paper 2 (Chapter 3) for a thorough discussion of these regions.

## Tuning study parameters
To maximize performance of operating characteristics under a given sample size the sgpvAM function allows the user to specify multiple wait time settings, frequency of looks, and number of steps before affirming a stopping rule.  (The wait time is the time until the expected Confidence Interval Width achieves a certain length or less).

## Operating characteristics under normal outcomes
After generating the operating characteristics under a fixed normal outcome, the user may use the locationShift function to obtain operating characteristics under a range of fixed treatment effects.  The function uses the saved MCMC replicates and adds to them if needed for additional monitoring.

## ECDF of sample size and bias
Once a study design has been selected based on average performance (sample size, bias, and error probabilities), the user may use the ecdf.sgpv function to see the empirical cumulative distribution across the MCMC replicates for sample size and bias under a specific design.  The user may see the estimated probability of the sample size exceeding a certain maximum sample size.

## General suggestions
Computations may be time consuming.  It is recommended to start with 1000 replicates to get a general sense of average sample size and error probabilities under a variety of investigated wait times and affirmation steps.  Investigating many wait times increases the computational burden.  It is also recommended to generate MCMC replicates in the (or one of the) mid point(s) between the Clinically Trivial and Highly Actionable Regions.  This is the region with greatest expected sample size and reduces the burden of the locationShift function to generate more data.

## Inputs


## Return values

The sgpvAM function returns a list with three elements: 

1.	mcmcMonitoring – the mcmcReplicates when outData is TRUE, 
2.	mcmcEndOfStudy – operating characteristics on average and ECDF for each combination of wait time and number of steps before affirming a stopping rule
3.	inputs – Inputs in to the sgpv function

As supporting material for the package, we have developed an extensive vignette that illustrates using sgpvAM to estimate and explore the impact of study design choices on Point Null Type I error, Power for a range of true effect sizes, average sample sizes, the distribution of possible sample sizes, and more. These include the types of figures and calculations that will be of particular interest to the traditional trialist. The full vignette may be found at https://github.com/chipmanj/sgpvAM or by loading the sgpvAM package and calling Vignette(package = "sgpvAM", topic = "README").  Three of the example figures are presented briefly below.
Figure 1 is a classical power curve which shows the probability the final CI will exclude the point null at various true effect sizes. The power when the true effect size is equal to the point null is the classical point null Type I error probability. The figure illustrates the impact of various wait times on the power curve. The second generation p-value adaptive design allows for designing trials with finite and infinite sample sizes in mind. We recommend presenting both. Figure 1 illustrates the infinite sample size. Notice the point null Type I error is bounded below 5% even when the maximum sample size is theoretically infinite. Under this framework, a study that stopped for reaching a maximum sample size could be restarted without concern of controlling point null Type I error.
Figure 2 displays the impact of increasing the affirmation steps on the average sample size. Increasing the affirmation steps has benefits in reducing bias, increasing interval coverage probabilities, and increasing the stability of conclusions particularly in the presence of a lag between recruitment and outcome observation. These benefits come with an increase in average sample size, particularly in between the bounds of the Trivial and Highly Actionable regions, i.e. where erroneous conclusions due to stopping too early are most likely. 
Non-adaptive studies are typically designed a with high probability of an inconclusive finding. Consider a non-adaptive study designed to have 80% power at a clinically highly actionable effect size. Such a study will include the point null in its final interval 20% of the time. It will include values from the null region with an even higher probability. Although designed to only stop when a clinically highly actionable conclusion has been found, second generation p-value adaptive monitored trials may yield a clinically inconclusive finding if the trial has a fixed maximum sample size and/or a lag between recruitment and outcome observation. This probability is highest in between the bounds of the Trivial and Highly Actionable regions. 
Figure 3 illustrates the control of this probability provided through increasing the affirmation steps in the presence of a 50 subject lag time. Even with this large lag, a relatively small affirmation step requirement bounds the probability of an inconclusive finding below 20%.  
 
   
# Practical Recommendations

Of key importance to classical trialists is controlling point null Type I Error and achieving a high probability of excluding the point null when the true effect size is clinically highly actionable. Of key importance to medical researchers is completing the study with a clinically highly actionable finding. We show that focusing on the later will achieve the former. When a study is not able to observe outcomes immediately, care should be taken to reduce the risk of stopping and then being inconclusive after observing the remaining observations.
To control error rates, one may change the clinical guideposts, reduce the number of times monitoring the study, and/or increase the number of steps before affirming a stopping rule.  Ideally, the clinical guideposts chosen for their clinical interpretation. We discourage altering them for the sake of operational characteristics.  Instead, we encourage optimizing operating characteristics through the waiting a period of time before monitoring and requiring a number of observations to pass until affirming an alert to stop the study.
We consider various wait times based upon the expected confidence interval width under an assumed outcome standard deviation.  Twenty thousand MCMC replicates of a study with standard normal outcomes are generated using the sgpvAM package under five one-sided hypotheses settings and five symmetric two-sided hypotheses.  The settings reflect situations where (Setting 1) the Trivial and Highly Actionable Effect bounds are both close to the point null of zero, (Settings 2-4) the Trivial Effect bound is close to the null and the Highly Actionable Effect is far from the point null, and (Setting 5) situations where the bound for Highly Actionable Effects is far from the null and the bound for Trivial Effects is increasingly close to the Highly Actionable Effect bound.  These results generalize to normal outcomes with clinical guideposts relative to the standard deviation.
For both one- and symmetric two-sided hypotheses, the probability of a Type I Error is minimized by waiting until the Confidence Interval Width is the midpoint between the Trivial and Highly Actionable Zones (Figure 4).  For example, a one-sided study with At Most Trivial Effects defined as (-∞, 0.1] and Highly Actionable Effects as [0.2, ∞) reduces the probability of a Type I Error by waiting until the Confidence Interval Width is 0.15.  In these simulations, the probability of a Type I Error remained less than or equal to 0.05 when waiting longer, until the Confidence Interval Width equaled the positive boundary of the Trivial Effects.
The following operating characteristics benefit from a longer wait time (i.e. waiting until the CI Width is more narrow): power (Figure 5); an interval null equivalent to Type I Error (Figures 7 and 8), Power (Figure 9), and Type Two Error (Figure 10); and the probability of stopping for conclusive observed outcomes yet becoming inconclusive after observing the remaining unobserved outcomes (Figure 11).  On the other hand, a shorter wait time yields smaller average sample sizes (Figure 6).  The gains in sample size diminishes once the wait time is the midpoint between the Trivial and Highly Actionable Zones.  
On whole, this suggests waiting no longer than this midpoint and may motivate waiting slightly longer (for a smaller Confidence Interval Width).  When the boundary of the Trivial Zone is close to half the boundary of the Highly Actionable Zone, it may be worthwhile to set the Confidence Interval wait time to the boundary of the Trivial Zone (refer to settings 3 and 4 in Figure 6 compared to setting 2).  Across these simulations, setting the wait width to one quarter between the Trivial and Highly Actionable boundaries balances well maximizing operating characteristics without a substantive increase in average observed sample size.  In the earlier one-sided example, this would be to wait until the expected Confidence Interval Width equals 0.125.
This leads us to some practical recommendations regarding wait time.  First, if the outcome’s variability is well known, set the wait time to one quarter of the distance between the Trivial and Highly Actionable boundaries.  Second, if the variability is not well known, error on over-assuming the variability.  This will result in setting a longer-wait time than needed.  In this instance, we suggest setting the Confidence Interval Width to the mid point between the Trivial and Highly Actionable boundaries.
Studies may have intermediate outcomes.  For effects that are neither Trivial nor Highly Actionable, there’s a very plausible chance the study ends conclusively for the outcomes observed yet becomes inconclusive after observing the outcomes of remaining study observations (Figure 11).  To reduce this risk, we recommend increasing the number of steps required to affirm stopping rules.

# Conclusion

We provide the sgpvAM package to provide greater ease of access to develop and study the operating characteristics of adaptive monitoring with the second generation p-value.  Based on simulations of normally distributed data, we recommend waiting until the expected Confidence Interval Width is one quarter the absolute distance between the Trivial and Highly Actionable Region boundaries.  When outcomes do not occur immediately, there is a risk of the study stopping then being inconclusive once all observations are observed.  This risk is reduced by requiring an increased number of steps before affirming an alert to stop the study. 
